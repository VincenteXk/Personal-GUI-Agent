"""
è¯­éŸ³ç®¡ç†æ¨¡å—

å°† dialogue.py çš„ VoiceAssistant é€‚é…ä¸º phone_agent æ¥å£
"""

import os
import sys
import queue
import io
import wave
import time
import asyncio
import threading
from typing import Optional


# å¯¼å…¥ VoiceAssistant
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
try:
    from dialogue import VoiceAssistant
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥ dialogue æ¨¡å—: {e}")
    VoiceAssistant = None


class VoiceManager:
    """
    è¯­éŸ³ç®¡ç†å™¨ï¼Œé€‚é… dialogue.py çš„ VoiceAssistant

    æä¾›ç»Ÿä¸€çš„è¯­éŸ³è¾“å…¥/è¾“å‡ºæ¥å£ï¼Œæ”¯æŒï¼š
    - è¯­éŸ³è¯†åˆ« (ASR)
    - æ–‡æœ¬è½¬è¯­éŸ³ (TTS)
    - åå°ç›‘å¬çº¿ç¨‹
    """

    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, model: str = "deepseek-chat"):
        """
        åˆå§‹åŒ–è¯­éŸ³ç®¡ç†å™¨

        Args:
            api_key: APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨dialogue.pyä¸­çš„é…ç½®ï¼‰
            base_url: APIåŸºç¡€URLï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨dialogue.pyé…ç½®ï¼‰
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        if VoiceAssistant is None:
            raise RuntimeError("VoiceAssistant æœªèƒ½æ­£ç¡®å¯¼å…¥ï¼Œè¯·æ£€æŸ¥ dialogue.py æ–‡ä»¶")

        self.assistant = VoiceAssistant()
        self.is_listening = False
        self.listener_threads = []

        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰é…ç½®ï¼Œè¦†ç›–é»˜è®¤é…ç½®
        if api_key:
            try:
                from openai import OpenAI
                self.assistant.client = OpenAI(
                    api_key=api_key,
                    base_url=base_url or "https://api.deepseek.com"
                )
            except ImportError:
                print("è­¦å‘Š: OpenAI åº“æœªå®‰è£…")

    def listen_and_transcribe(self, timeout: int = 5) -> Optional[str]:
        """
        ç›‘å¬è¯­éŸ³å¹¶è½¬å½•ä¸ºæ–‡æœ¬

        Args:
            timeout: ç­‰å¾…éŸ³é¢‘æ•°æ®çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            str: è¯†åˆ«å‡ºçš„æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°åˆ™è¿”å›None
        """
        try:
            audio_data = self.assistant.audio_queue.get(timeout=timeout)

            # ä½¿ç”¨ASRæ¨¡å‹è¯†åˆ«
            audio_stream = io.BytesIO()
            with wave.open(audio_stream, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(16000)
                wf.writeframes(audio_data)

            audio_stream.seek(0)
            print(f"è¯†åˆ«ä¸­...({len(audio_data)/16000:.2f}ç§’)")

            res = self.assistant.asr_model.generate(
                input=audio_stream,
                cache={},
                language="auto",
                use_itn=False
            )

            if res:
                text = res[0]['text'].split(">")[-1].strip().replace(" ", "")
                return text if text else None
            return None

        except queue.Empty:
            print("æœªæ£€æµ‹åˆ°è¯­éŸ³")
            return None
        except Exception as e:
            print(f"è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
            return None

    def speak(self, text: str) -> None:
        """
        æ–‡æœ¬è½¬è¯­éŸ³å¹¶æ’­æ”¾

        Args:
            text: è¦æ’­æ”¾çš„æ–‡æœ¬
        """
        try:
            asyncio.run(self.assistant.edge_tts_sync(text))
        except Exception as e:
            print(f"è¯­éŸ³åˆæˆå’Œæ’­æ”¾é”™è¯¯: {e}")

    def start_listening(self) -> None:
        """
        å¯åŠ¨åå°ç›‘å¬çº¿ç¨‹

        å¯åŠ¨ä¸¤ä¸ªå®ˆæŠ¤çº¿ç¨‹ï¼š
        - audio_recorder: å½•åˆ¶éŸ³é¢‘å¹¶è¿›è¡ŒVADæ£€æµ‹
        - process_audio: å¤„ç†è¯†åˆ«å’ŒLLMå›å¤
        """
        if self.is_listening:
            print("ç›‘å¬å·²åœ¨è¿è¡Œ")
            return

        self.is_listening = True
        self.assistant.recording_active = True

        # å¯åŠ¨å½•éŸ³çº¿ç¨‹
        recorder_thread = threading.Thread(
            target=self.assistant.audio_recorder,
            daemon=True,
            name="VoiceRecorder"
        )
        recorder_thread.start()
        self.listener_threads.append(recorder_thread)

        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        processor_thread = threading.Thread(
            target=self.assistant.process_audio,
            daemon=True,
            name="VoiceProcessor"
        )
        processor_thread.start()
        self.listener_threads.append(processor_thread)

        print("ğŸ¤ è¯­éŸ³ç›‘å¬å·²å¯åŠ¨")

    def stop_listening(self) -> None:
        """åœæ­¢åå°ç›‘å¬çº¿ç¨‹"""
        if not self.is_listening:
            print("ç›‘å¬æœªè¿è¡Œ")
            return

        self.is_listening = False
        self.assistant.recording_active = False

        # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤š5ç§’ï¼‰
        for thread in self.listener_threads:
            thread.join(timeout=5)

        self.listener_threads = []
        print("ğŸ¤ è¯­éŸ³ç›‘å¬å·²åœæ­¢")

    def is_running(self) -> bool:
        """
        æ£€æŸ¥ç›‘å¬æ˜¯å¦æ­£åœ¨è¿è¡Œ

        Returns:
            bool: æ˜¯å¦æ­£åœ¨è¿è¡Œ
        """
        return self.is_listening and self.assistant.recording_active

    def get_conversation_history(self):
        """
        è·å–å¯¹è¯å†å²è®°å½•

        Returns:
            list: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
        """
        return self.assistant.messages

    def clear_conversation_history(self) -> None:
        """æ¸…ç©ºå¯¹è¯å†å²è®°å½•ï¼Œä»…ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯"""
        if len(self.assistant.messages) > 1:
            system_message = self.assistant.messages[0]
            self.assistant.messages = [system_message]
            print("âœ… å¯¹è¯å†å²å·²æ¸…ç©º")
