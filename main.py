#!/usr/bin/env python3
"""
PersonalUI - ä¸ªæ€§åŒ–GUI Agentç³»ç»Ÿ

åŸºäºAutoGLMæ¡†æ¶çš„ä¸ªæ€§åŒ–GUI agentï¼Œä½¿ç”¨GraphRAGå­˜å‚¨ç”¨æˆ·ä¹ æƒ¯ï¼Œ
é€šè¿‡learning modeå­¦ä¹ ç”¨æˆ·è¡Œä¸ºå¹¶æ›´æ–°åˆ°GraphRAGï¼Œæ”¯æŒè¯­éŸ³æŒ‡ä»¤æ“ä½œã€‚

Usage:
    python main.py [OPTIONS]
"""

import argparse
import os
import sys
import json
import time
import threading
import subprocess
import shutil
from typing import Dict, Any, Optional
import requests  # æ·»åŠ requestsç”¨äºAPIè°ƒç”¨

# å¯¼å…¥AutoGLM
from src.AutoGLM.agent import PhoneAgent, AgentConfig
from src.AutoGLM.model import ModelConfig

# å¯¼å…¥è¯­éŸ³æ¨¡å—
from src.AutoGLM.voice import VoiceAssistant

# å¯¼å…¥learning_modeç›¸å…³æ¨¡å—
from src.learning.behavior_analyzer import BehaviorAnalyzer
from src.learning.vlm_analyzer import VLMAnalyzer

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from src.core.refiner import InstructionRefiner

class PersonalUI:
    """PersonalUIç³»ç»Ÿä¸»ç±»ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—"""

    def __init__(self, args, config_path: str = "config.json"):
        """
        åˆå§‹åŒ–PersonalUIç³»ç»Ÿ

        Args:
            args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.args = args
        # åŠ è½½é…ç½®å¹¶åˆå¹¶å‘½ä»¤è¡Œå‚æ•°
        self.config = self._load_and_merge_config(config_path)
        self.refiner = InstructionRefiner(model_config=self._get_model_config())
        self.phone_agent = None
        self.behavior_analyzer = BehaviorAnalyzer()
        self.vlm_analyzer = None
        self.graphrag_api_url = self.config["graphrag_config"]["api_url"]
        self._init_modules()

    def _load_and_merge_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶å¹¶ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–"""
        # é»˜è®¤é…ç½®
        config = {
            "model_config": {
                "base_url": "http://localhost:8000/v1",
                "model": "autoglm-phone-9b",
                "api_key": "EMPTY"
            },
            "agent_config": {
                "max_steps": 100,
                "device_id": None,
                "lang": "cn"
            },
            "learning_config": {
                "api_key": "",
                "model": "glm-4.1v-thinking-flash",
                "output_dir": "data"
            },
            "graphrag_config": {
                "config_path": "graphrag/config.yaml",
                "max_concurrent_tasks": 3,
                "api_url": "http://localhost:8001"  # æ·»åŠ GraphRAG APIåœ°å€
            }
        }

        # åŠ è½½ JSON
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                user_config = json.load(f)
                self._deep_update(config, user_config)

        # å‘½ä»¤è¡Œå‚æ•°è¦†ç›– (CLI Args > Config File > Defaults)
        if hasattr(self.args, 'base_url') and self.args.base_url:
            config["model_config"]["base_url"] = self.args.base_url
        if hasattr(self.args, 'model') and self.args.model:
            config["model_config"]["model"] = self.args.model
        if hasattr(self.args, 'apikey') and self.args.apikey and self.args.apikey != "EMPTY":
            config["model_config"]["api_key"] = self.args.apikey

        # è®¾å¤‡IDè¦†ç›–
        if hasattr(self.args, 'device_id') and self.args.device_id:
            config["agent_config"]["device_id"] = self.args.device_id

        # Max stepsè¦†ç›–
        if hasattr(self.args, 'max_steps') and self.args.max_steps != 100:
            config["agent_config"]["max_steps"] = self.args.max_steps

        # è¯­è¨€è¦†ç›–
        if hasattr(self.args, 'lang') and self.args.lang:
            config["agent_config"]["lang"] = self.args.lang

        return config
    
    def _deep_update(self, base_dict: Dict[str, Any], update_dict: Dict[str, Any]) -> None:
        """é€’å½’æ›´æ–°å­—å…¸"""
        for key, value in update_dict.items():
            if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def _get_model_config(self) -> ModelConfig:
        """è·å–æ¨¡å‹é…ç½®å¯¹è±¡"""
        return ModelConfig(
            base_url=self.config["model_config"]["base_url"],
            model_name=self.config["model_config"]["model"],
            api_key=self.config["model_config"]["api_key"],
            lang=self.config["agent_config"]["lang"]
        )

    def _init_modules(self):
        """åˆå§‹åŒ–å„ä¸ªæ¨¡å—"""
        print("ğŸš€ åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—...")
        model_conf = self._get_model_config()

        # åˆå§‹åŒ– PhoneAgent
        agent_conf = AgentConfig(
            max_steps=self.config["agent_config"]["max_steps"],
            device_id=self.config["agent_config"]["device_id"],
            lang=self.config["agent_config"]["lang"]
        )
        self.phone_agent = PhoneAgent(model_config=model_conf, agent_config=agent_conf)

        # åˆå§‹åŒ– VLM (ç”¨äºæ„ŸçŸ¥)
        learn_conf = self.config["learning_config"]
        if learn_conf["api_key"]:
            self.vlm_analyzer = VLMAnalyzer(
                api_key=learn_conf["api_key"],
                model=learn_conf["model"],
                api_url=learn_conf.get("api_url")
            )
            print("âœ… VLM Analyzer å·²é…ç½®")
        else:
            print("âš ï¸ VLM Analyzer æœªé…ç½®ï¼Œè¡Œä¸ºå­¦ä¹ æ¨¡å¼ä¸å¯ç”¨")

        # æ£€æŸ¥GraphRAG APIæ˜¯å¦å¯ç”¨
        if self._check_graphrag_api():
            print("âœ… GraphRAG APIè¿æ¥æˆåŠŸ")
        else:
            print("âš ï¸ æ— æ³•è¿æ¥åˆ°GraphRAG API")
    
    def _check_graphrag_api(self) -> bool:
        """æ£€æŸ¥GraphRAG APIæ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.graphrag_api_url}/health")
            return response.status_code == 200
        except Exception as e:
            print(f"GraphRAG APIè¿æ¥å¤±è´¥: {e}")
            return False

    def start_learning_mode(self, duration: Optional[int] = None):
        """å¯åŠ¨å­¦ä¹ æ¨¡å¼"""
        print("ğŸ“ å¯åŠ¨å­¦ä¹ æ¨¡å¼...")
        
        session_id,data_for_vlm = self.behavior_analyzer.collect_and_process(duration_seconds=duration)

        if session_id and self.vlm_analyzer:
            # ç”Ÿæˆå’Œåˆ†æLLMæ•°æ®ï¼ˆä¼ é€’ä¼šè¯IDï¼‰
            print("ä½¿ç”¨VLMåˆ†æç”¨æˆ·è¡Œä¸ºæ•°æ®...")

            vlm_analysis = self.vlm_analyzer.analyze_session_with_screenshots(data_for_vlm)

            with open('data/sessions/{0}/analysis/{0}_vlm.json'.format(session_id), "w", encoding="utf-8") as f:
                json.dump(vlm_analysis, f, ensure_ascii=False, indent=2)

        elif not self.vlm_analyzer:
            print("âš ï¸ VLM Analyzer æœªé…ç½®ï¼Œè·³è¿‡è§†è§‰åˆ†æ")
        else:
            print("âš ï¸ æœªæ”¶é›†åˆ°è¶³å¤Ÿçš„ä¼šè¯æ•°æ®")
    
    def _store_analysis_to_graphrag(self, analysis_result: Dict[str, Any]):
        """å°†åˆ†æç»“æœå­˜å‚¨åˆ°GraphRAG API"""
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GraphRAG API
        if not self._check_graphrag_api():
            print("âš ï¸ GraphRAG APIä¸å¯ç”¨ï¼Œè·³è¿‡å­˜å‚¨åˆ†æç»“æœ")
            return
        
        # æå–åˆ†æç»“æœä¸­çš„å…³é”®ä¿¡æ¯
        if "analysis" in analysis_result and "analysis" in analysis_result["analysis"]:
            analysis = analysis_result["analysis"]["analysis"]
            
            # æ„å»ºä»»åŠ¡æè¿°
            task_description = f"ç”¨æˆ·è¡Œä¸ºåˆ†æ: {analysis.get('main_action', 'æœªçŸ¥è¡Œä¸º')}"
            if "intent" in analysis:
                task_description += f", æ„å›¾: {analysis['intent']}"
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                "task_description": task_description,
                "analysis_result": analysis_result
            }
            
            try:
                # æäº¤åˆ°GraphRAG API
                response = requests.post(f"{self.graphrag_api_url}/tasks", json=data, timeout=30)
                
                if response.status_code == 200:
                    task_id = response.json().get("task_id", "unknown")
                    print(f"âœ… åˆ†æç»“æœå·²æäº¤åˆ°GraphRAGï¼Œä»»åŠ¡ID: {task_id}")
                else:
                    print(f"âŒ æäº¤åˆ°GraphRAGå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
            except requests.exceptions.ConnectionError:
                print(f"âŒ æ— æ³•è¿æ¥åˆ°GraphRAG APIæœåŠ¡å™¨: {self.graphrag_api_url}")
            except requests.exceptions.Timeout:
                print(f"âŒ è¿æ¥åˆ°GraphRAG APIè¶…æ—¶: {self.graphrag_api_url}")
            except Exception as e:
                print(f"âŒ æäº¤åˆ°GraphRAG APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        else:
            print("âš ï¸ æ— æ•ˆçš„åˆ†æç»“æœæ ¼å¼ï¼Œè·³è¿‡å­˜å‚¨")
    
    def start_execution_mode(self, task: str, voice_mode: bool = False):
        """å¯åŠ¨æ‰§è¡Œæ¨¡å¼"""
        print(f"ğŸš€ å¯åŠ¨æ‰§è¡Œæ¨¡å¼ï¼Œä»»åŠ¡: {task}")
        
        # åˆå§‹åŒ–è¯­éŸ³æ¨¡å—
        voice_assistant = None
        if voice_mode:
            from src.AutoGLM.voice import VoiceAssistant
            voice_assistant = VoiceAssistant()
            print("ğŸ¤ è¯­éŸ³æ¨¡å¼å·²å°±ç»ªï¼")

        # 1. ä½¿ç”¨InstructionRefinerä¼˜åŒ–æŒ‡ä»¤
        refined_task = self.refiner.refine_task(task)

        # 2. ä½¿ç”¨PhoneAgentæ‰§è¡Œä»»åŠ¡
        result = self.phone_agent.run(refined_task)
        print(f"ä»»åŠ¡æ‰§è¡Œç»“æœ: {result}")
        
        # å¦‚æœæ˜¯è¯­éŸ³æ¨¡å¼ï¼Œå°†ç»“æœè½¬æ¢ä¸ºè¯­éŸ³æ’­æ”¾
        if voice_mode and voice_assistant and result:
            voice_assistant.speak(result)
        
        return result
    
    def start_interactive_mode(self, voice_mode: bool = False):
        """å¯åŠ¨äº¤äº’æ¨¡å¼"""
        # åˆå§‹åŒ–è¯­éŸ³æ¨¡å—
        voice_assistant = None
        if voice_mode:
            from src.AutoGLM.voice import VoiceAssistant
            voice_assistant = VoiceAssistant()
            print("ğŸ¤ è¯­éŸ³æ¨¡å¼å·²å°±ç»ªï¼")
        
        print("\nè¿›å…¥äº¤äº’æ¨¡å¼ã€‚è¾“å…¥ 'quit' é€€å‡ºã€‚\n")
    
        while True:
            # åˆ¤æ–­æ˜¯è¯­éŸ³è¾“å…¥è¿˜æ˜¯æ–‡å­—è¾“å…¥
            if voice_mode and voice_assistant:
                # 1. è¯­éŸ³æ¨¡å¼é€»è¾‘
                user_input = input("\n[æŒ‰å›è½¦é”®å¼€å§‹è¯´è¯] (è¾“å…¥ 'q' é€€å‡º) >> ").strip()
                
                if user_input.lower() in ("quit", "exit", "q"):
                    print("å†è§!")
                    break
                
                # è°ƒç”¨è¯­éŸ³è¯†åˆ«
                audio_data = voice_assistant.single_record()
                if not audio_data:
                    print("âš ï¸ æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•")
                    continue
                    
                task = voice_assistant.asr_transcribe(audio_data)
                
                if not task:
                    print("âš ï¸ è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•")
                    continue
                    
                print(f"ğŸ—£ï¸ è¯†åˆ«åˆ°æŒ‡ä»¤: {task}")
                
                # (å¯é€‰) è®©ç”¨æˆ·ç¡®è®¤ä¸€ä¸‹è¯†åˆ«æ˜¯å¦å‡†ç¡®
                confirm = input("ç¡®è®¤æ‰§è¡Œ? [Y/n]: ").strip().lower()
                if confirm == 'n':
                    print("å·²å–æ¶ˆï¼Œè¯·é‡æ–°å½•å…¥ã€‚")
                    continue

            else:
                # 2. åŸæœ‰çš„æ–‡å­—è¾“å…¥é€»è¾‘
                task = input("è¾“å…¥æ‚¨çš„ä»»åŠ¡: ").strip()
                
            if task.lower() in ("quit", "exit", "q"):
                print("å†è§!")
                break

            if not task:
                continue

            print()
            try:
                refined_task = self.refiner.refine_task(task)
                result = self.phone_agent.run(refined_task)
                print(f"\nç»“æœ: {result}\n")
                
                # å¦‚æœæ˜¯è¯­éŸ³æ¨¡å¼ï¼Œå°†ç»“æœè½¬æ¢ä¸ºè¯­éŸ³æ’­æ”¾
                if voice_mode and voice_assistant and result:
                    voice_assistant.speak(result)
                    
                self.phone_agent.reset()
            except Exception as e:
                print(f"âŒ æ‰§è¡Œä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    import argparse

    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description="PersonalUI - ä¸ªæ€§åŒ–GUI Agentç³»ç»Ÿ")
    parser.add_argument("--base-url", type=str, default=None, help="Model API base URL")
    parser.add_argument("--model", type=str, default=None, help="Model name")
    parser.add_argument("--apikey", type=str, default=None, help="API key")
    parser.add_argument("--device-id", type=str, default=None, help="Device ID")
    parser.add_argument("--max-steps", type=int, default=100, help="Max steps")
    parser.add_argument("--lang", type=str, default="cn", help="Language (cn/en)")
    parser.add_argument("--mode", type=str, default="interactive",
                       choices=["interactive", "learning", "execution"],
                       help="Running mode")

    args = parser.parse_args()

    # åˆå§‹åŒ– PersonalUI
    app = PersonalUI(args)

    # æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.mode == "learning":
        app.start_learning_mode(duration=60)
    elif args.mode == "execution":
        app.start_execution_mode()
    else:
        # è¿è¡Œäº¤äº’æ¨¡å¼
        app.start_interactive_mode()


if __name__ == "__main__":
    main()